{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Fitting a neural network to MNIST"
      ],
      "metadata": {
        "id": "GKge6kRjTF1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "EXZXS6JdTa8O"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZL0ZZtb_S02o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d47e9b2-6729-450d-fae9-ef0eb1325e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the j-th image\n",
        "j = 991\n",
        "fig = plt.figure\n",
        "plt.imshow(train_images[j], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4yKaiM6nTPM2",
        "outputId": "09e3c856-b2ff-432d-9532-6e38a39e76ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "gF3XV-jHTZVD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "id": "Z6v8kCEsTlvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea5e6b0-ccdd-4114-8a99-cb2d5ec11a05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "gPpKx1u6ToCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\", \\\n",
        "              loss = \"sparse_catergorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "C_yvHFjjTp4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "rZTUyVFpavb5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', \n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Hl99kB8Ra2ou"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-Yaca1Ra_7e",
        "outputId": "d322bbd3-a13b-4e76-a4cd-e60dd40fb96d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.2505 - accuracy: 0.9272\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1016 - accuracy: 0.9697\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0683 - accuracy: 0.9799\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.0498 - accuracy: 0.9849\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.0376 - accuracy: 0.9890\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb648477d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeYyN29bboCP",
        "outputId": "8a77d214-be44-4d5f-ae05-bf435b87b96b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.1052845e-09, 3.7426461e-11, 1.8570084e-06, ..., 9.9998760e-01,\n",
              "        2.7989442e-08, 1.2365891e-07],\n",
              "       [1.0612247e-10, 4.3609975e-07, 9.9999952e-01, ..., 2.2120263e-18,\n",
              "        1.9425929e-08, 5.3211549e-17],\n",
              "       [7.7594633e-09, 9.9977869e-01, 2.0589710e-05, ..., 9.5653348e-05,\n",
              "        9.0392961e-05, 1.9267237e-07],\n",
              "       ...,\n",
              "       [1.4545377e-13, 3.8362521e-11, 7.7752034e-11, ..., 3.2495332e-06,\n",
              "        3.4104539e-06, 1.8298395e-05],\n",
              "       [3.1098405e-11, 9.4057303e-13, 4.5256994e-14, ..., 7.3526401e-13,\n",
              "        1.5416289e-06, 1.9282322e-14],\n",
              "       [7.1914648e-11, 1.1346526e-17, 6.8140645e-12, ..., 5.1079263e-17,\n",
              "        6.1689201e-13, 1.5669814e-13]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reimplementing the model from scratch in TensorFlow"
      ],
      "metadata": {
        "id": "gZtBitYgTrtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A single layer\n",
        "\n",
        "$Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$\n",
        "\n",
        "$A^{[l]}=g(Z^{[l]})$\n"
      ],
      "metadata": {
        "id": "8RseWjP8UoKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compose a single layer\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        self.activation = activation\n",
        "\n",
        "        w_shape = (input_size, output_size)\n",
        "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "        self.W = tf.Variable(w_initial_value)\n",
        "\n",
        "        b_shape = (output_size,)\n",
        "        b_initial_value = tf.zeros(b_shape)\n",
        "        self.b = tf.Variable(b_initial_value)\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b]"
      ],
      "metadata": {
        "id": "4c1AEeGPTuLK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compose the layers together\n",
        "\n",
        "Each layer is a function\n",
        "\n",
        "for $l=1,..., L$,\n",
        "\n",
        "$Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$\n",
        "\n",
        "$A^{[l]}=g(Z^{[l]})$\n",
        "\n",
        "where $A^{[0]} = X$ for the first layer"
      ],
      "metadata": {
        "id": "rNf1VfUxU6Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compose the layers together\n",
        "# take layers one by one, appply recursively to layers \n",
        "\n",
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        weights = []\n",
        "        for layer in self.layers:\n",
        "            weights += layer.weights\n",
        "\n",
        "        return weights"
      ],
      "metadata": {
        "id": "ywuX9AYZUe-t"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "7W5X3IFte4pk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(model.weights) == 4"
      ],
      "metadata": {
        "id": "59uDTp0eVqop"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a batch of data\n",
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ],
      "metadata": {
        "id": "DAFuANxoVwWG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient descent for neural networks\n",
        "\n",
        "Hand derivations\n",
        "\n",
        "$dz^{[2]} = a^{[2]} - y$\n",
        "\n",
        "$dW^{[2]} = dz^{[2]} a^{[1]\\top}$\n",
        "\n",
        "$db^{[2]} = dz^{[2]}$\n",
        "\n",
        "$dz^{[1]} = W^{[2]\\top}dz^{[2]}*g^{[1]'}(z^{[1]})$\n",
        "\n",
        "$dW^{[1]} = dz^{[1]} x^{\\top}$\n",
        "\n",
        "$db^{[1]} = dz^{[1]}$\n",
        "\n",
        "Use gradient tape!"
      ],
      "metadata": {
        "id": "VhD5dIoOWX_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images_batch)\n",
        "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(labels_batch, predictions)\n",
        "        average_loss = tf.reduce_mean(per_sample_losses)\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss"
      ],
      "metadata": {
        "id": "JoDx0yR_V-B8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient descent\n",
        "\n",
        "$W^{[1]} \\leftarrow W^{[1]} - \\alpha \\cdot dW^{[1]}$\n",
        "\n",
        "$W^{[2]} \\leftarrow W^{[2]} - \\alpha \\cdot dW^{[2]}$\n",
        "\n",
        "$b^{[1]} \\leftarrow b^{[1]} - \\alpha \\cdot db^{[1]}$\n",
        "\n",
        "$b^{[2]} \\leftarrow b^{[2]} - \\alpha \\cdot db^{[2]}$"
      ],
      "metadata": {
        "id": "f5WRUGuCXdFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning_rate = 1e-3"
      ],
      "metadata": {
        "id": "LeUODv1tZnB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_weights(gradients, weights):\n",
        "  for g, w in zip(gradients, weights):\n",
        "    w.assign_sub(g * learning_rate)\n"
      ],
      "metadata": {
        "id": "aHSJpzPQXOqg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alternative implementation with optimizers\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "optimizer = optimizers.SGD(learning_rate = 1e-3)\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "  optimizer.apply_gradients(zip(gradients, weights))"
      ],
      "metadata": {
        "id": "CI3-gYFgXWjA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The full training loop"
      ],
      "metadata": {
        "id": "NRb7u3x6X_ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "  for epoch_counter in range(epochs):\n",
        "    print(f\"Epoch {epoch_counter}\")\n",
        "    batch_generator = BatchGenerator(images, labels)\n",
        "    for batch_counter in range(batch_generator.num_batches):\n",
        "      images_batch, labels_batch = batch_generator.next()\n",
        "      loss = one_training_step(model, images_batch, labels_batch)\n",
        "      if batch_counter % 100 == 0:\n",
        "        print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
      ],
      "metadata": {
        "id": "tarTgDRXX7jo"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit the model using our implementation from scratch"
      ],
      "metadata": {
        "id": "lS4DvFWRYCTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ],
      "metadata": {
        "id": "rpZgjdFFXzSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60588738-0250-4a7c-86a2-507c366bb7de"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "loss at batch 0: 0.71\n",
            "loss at batch 100: 0.74\n",
            "loss at batch 200: 0.64\n",
            "loss at batch 300: 0.70\n",
            "loss at batch 400: 0.76\n",
            "Epoch 1\n",
            "loss at batch 0: 0.65\n",
            "loss at batch 100: 0.69\n",
            "loss at batch 200: 0.59\n",
            "loss at batch 300: 0.66\n",
            "loss at batch 400: 0.72\n",
            "Epoch 2\n",
            "loss at batch 0: 0.62\n",
            "loss at batch 100: 0.65\n",
            "loss at batch 200: 0.55\n",
            "loss at batch 300: 0.63\n",
            "loss at batch 400: 0.69\n",
            "Epoch 3\n",
            "loss at batch 0: 0.59\n",
            "loss at batch 100: 0.61\n",
            "loss at batch 200: 0.52\n",
            "loss at batch 300: 0.60\n",
            "loss at batch 400: 0.67\n",
            "Epoch 4\n",
            "loss at batch 0: 0.56\n",
            "loss at batch 100: 0.58\n",
            "loss at batch 200: 0.50\n",
            "loss at batch 300: 0.57\n",
            "loss at batch 400: 0.64\n",
            "Epoch 5\n",
            "loss at batch 0: 0.54\n",
            "loss at batch 100: 0.55\n",
            "loss at batch 200: 0.48\n",
            "loss at batch 300: 0.55\n",
            "loss at batch 400: 0.62\n",
            "Epoch 6\n",
            "loss at batch 0: 0.52\n",
            "loss at batch 100: 0.53\n",
            "loss at batch 200: 0.46\n",
            "loss at batch 300: 0.53\n",
            "loss at batch 400: 0.61\n",
            "Epoch 7\n",
            "loss at batch 0: 0.50\n",
            "loss at batch 100: 0.51\n",
            "loss at batch 200: 0.44\n",
            "loss at batch 300: 0.52\n",
            "loss at batch 400: 0.59\n",
            "Epoch 8\n",
            "loss at batch 0: 0.49\n",
            "loss at batch 100: 0.49\n",
            "loss at batch 200: 0.43\n",
            "loss at batch 300: 0.50\n",
            "loss at batch 400: 0.58\n",
            "Epoch 9\n",
            "loss at batch 0: 0.48\n",
            "loss at batch 100: 0.48\n",
            "loss at batch 200: 0.41\n",
            "loss at batch 300: 0.49\n",
            "loss at batch 400: 0.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the model"
      ],
      "metadata": {
        "id": "3xEb9pqUYMG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(test_images)"
      ],
      "metadata": {
        "id": "hlaxRVJvYNz4"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predictions.numpy()\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == test_labels\n",
        "print(f\"accuracy: {matches.mean():.2f}\")"
      ],
      "metadata": {
        "id": "WFtewkDaY0kg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d473523-ebe0-4289-be04-b250fa857339"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.85\n"
          ]
        }
      ]
    }
  ]
}