{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtZxbW5tmBQm"
      },
      "source": [
        "**Notebook credit**: Based on the original D2L notebook [here](https://github.com/d2l-ai/d2l-tensorflow-colab/blob/master/chapter_convolutional-neural-networks/lenet.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "z28SxNx1mBQq"
      },
      "source": [
        "# Convolutional Neural Networks (LeNet)\n",
        "\n",
        "We now have all the ingredients required to assemble\n",
        "a fully-functional CNN.\n",
        "In our earlier encounter with image data,\n",
        "we applied\n",
        "a softmax regression model \n",
        "and\n",
        "an MLP model \n",
        "to MNIST dataset.\n",
        "To make such data amenable to softmax regression and MLPs,\n",
        "we first flattened each image from a $28\\times28$ matrix\n",
        "into a fixed-length $784$-dimensional vector,\n",
        "and thereafter processed them with fully-connected layers.\n",
        "Now that we have a handle on convolutional layers,\n",
        "we can retain the spatial structure in our images.\n",
        "As an additional benefit of replacing fully-connected layers with convolutional layers,\n",
        "we will enjoy more parsimonious models that require far fewer parameters.\n",
        "\n",
        "In this section, we will introduce *LeNet*,\n",
        "among the first published CNNs\n",
        "to capture wide attention for its performance on computer vision tasks.\n",
        "The model was introduced by (and named for) Yann LeCun,\n",
        "then a researcher at AT&T Bell Labs,\n",
        "for the purpose of recognizing handwritten digits in images.\n",
        "This work represented the culmination\n",
        "of a decade of research developing the technology.\n",
        "In 1989, LeCun published the first study to successfully\n",
        "train CNNs via backpropagation.\n",
        "\n",
        "\n",
        "At the time LeNet achieved outstanding results\n",
        "matching the performance of support vector machines,\n",
        "then a dominant approach in supervised learning.\n",
        "LeNet was eventually adapted to recognize digits\n",
        "for processing deposits in ATM machines.\n",
        "To this day, some ATMs still run the code\n",
        "that Yann and his colleague Leon Bottou wrote in the 1990s!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## LeNet\n",
        "\n",
        "At a high level, (**LeNet (LeNet-5) consists of two parts:\n",
        "(i) a convolutional encoder consisting of two convolutional layers; and\n",
        "(ii) a dense block consisting of three fully-connected layers**);\n",
        "The architecture is summarized below.\n",
        "\n",
        "![Data flow in LeNet. The input is a handwritten digit, the output a probability over 10 possible outcomes.](http://d2l.ai/_images/lenet.svg)\n",
        "\n",
        "\n",
        "The basic units in each convolutional block\n",
        "are a convolutional layer, a sigmoid activation function,\n",
        "and a subsequent average pooling operation.\n",
        "Note that while ReLUs and max-pooling work better,\n",
        "these discoveries had not yet been made in the 1990s.\n",
        "Each convolutional layer uses a $5\\times 5$ kernel\n",
        "and a sigmoid activation function.\n",
        "These layers map spatially arranged inputs\n",
        "to a number of two-dimensional feature maps, typically\n",
        "increasing the number of channels.\n",
        "The first convolutional layer has 6 output channels,\n",
        "while the second has 16.\n",
        "Each $2\\times2$ pooling operation (stride 2)\n",
        "reduces dimensionality by a factor of $4$ via spatial downsampling.\n",
        "The convolutional block emits an output with shape given by\n",
        "(batch size, number of channel, height, width).\n",
        "\n",
        "In order to pass output from the convolutional block\n",
        "to the dense block,\n",
        "we must flatten each example in the minibatch.\n",
        "In other words, we take this four-dimensional input and transform it\n",
        "into the two-dimensional input expected by fully-connected layers:\n",
        "as a reminder, the two-dimensional representation that we desire uses the first dimension to index examples in the minibatch\n",
        "and the second to give the flat vector representation of each example.\n",
        "LeNet's dense block has three fully-connected layers,\n",
        "with 120, 84, and 10 outputs, respectively.\n",
        "Because we are still performing classification,\n",
        "the 10-dimensional output layer corresponds\n",
        "to the number of possible output classes.\n",
        "\n",
        "While getting to the point where you truly understand\n",
        "what is going on inside LeNet may have taken a bit of work,\n",
        "hopefully the following code snippet will convince you\n",
        "that implementing such models with modern deep learning frameworks\n",
        "is remarkably simple.\n",
        "We need only to instantiate a `Sequential` block\n",
        "and chain together the appropriate layers.\n"
      ],
      "metadata": {
        "id": "EIIHdUpl7VHV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "origin_pos": 3,
        "tab": [
          "tensorflow"
        ],
        "id": "IvdOvY0ZmBQs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 4,
        "id": "gOXF-qkHmBQt"
      },
      "source": [
        "We took a small liberty with the original model,\n",
        "removing the Gaussian activation in the final layer.\n",
        "Other than that, this network matches\n",
        "the original LeNet-5 architecture.\n",
        "\n",
        "By passing a single-channel (black and white)\n",
        "$28 \\times 28$ image through the network\n",
        "and printing the output shape at each layer,\n",
        "we can [**inspect the model**] to make sure\n",
        "that its operations line up with\n",
        "what we expect from the figure above.\n",
        "\n",
        "![Compressed notation for LeNet-5.](https://github.com/d2l-ai/d2l-tensorflow-colab/blob/master/img/lenet-vert.svg?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 8,
        "id": "78d-m1ygmBQu"
      },
      "source": [
        "Note that the height and width of the representation\n",
        "at each layer throughout the convolutional block\n",
        "is reduced (compared with the previous layer).\n",
        "The first convolutional layer uses 2 pixels of padding\n",
        "to compensate for the reduction in height and width\n",
        "that would otherwise result from using a $5 \\times 5$ kernel.\n",
        "In contrast, the second convolutional layer forgoes padding,\n",
        "and thus the height and width are both reduced by 4 pixels.\n",
        "As we go up the stack of layers,\n",
        "the number of channels increases layer-over-layer\n",
        "from 1 in the input to 6 after the first convolutional layer\n",
        "and 16 after the second convolutional layer.\n",
        "However, each pooling layer halves the height and width.\n",
        "Finally, each fully-connected layer reduces dimensionality,\n",
        "finally emitting an output whose dimension\n",
        "matches the number of classes.\n",
        "\n",
        "\n",
        "\n",
        "## Training\n",
        "\n",
        "Now that we have implemented the model,\n",
        "let us [**run an experiment to see how LeNet fares on Fashion-MNIST**].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "origin_pos": 9,
        "tab": [
          "tensorflow"
        ],
        "id": "b8-dzxrsmBQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94166109-9f39-43f3-9721-66d04ac58bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 3s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "# generally alternate between conv and pooling layers \n",
        "# only do padding with input layer, not intermediate layers\n",
        "# flatten before combining with dense layers\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2DTranspose(filters = 6, kernel_size = 5, activation = 'sigmoid', padding = 'same', input_shape = (28, 28, 1)), \n",
        "    layers.AvgPool2D(pool_size = 2, strides = 2), \n",
        "    layers.Conv2D(filters = 16, kernel_size = 5, activation = 'sigmoid'),\n",
        "    layers.AvgPool2D(pool_size = 2, strides = 2), \n",
        "    layers.Flatten(), \n",
        "    layers.Dense(120, activation = 'sigmoid'),\n",
        "    layers.Dense(84, activation = 'sigmoid'), \n",
        "    layers.Dense(10, activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "SCFlRVAc8Wdm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'rmsprop', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "_2mtUFCO9wbS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# higher accuracy, less prone to overfiit\n",
        "history = model.fit(x_train, y_train, epochs = num_epochs, batch_size = batch_size, validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRE18zrb93NG",
        "outputId": "a863165b-9d88-4a34-83cd-432826ee74be"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "188/188 [==============================] - 10s 10ms/step - loss: 1.7503 - accuracy: 0.3957 - val_loss: 1.0713 - val_accuracy: 0.6194\n",
            "Epoch 2/20\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.9122 - accuracy: 0.6690 - val_loss: 0.8037 - val_accuracy: 0.7057\n",
            "Epoch 3/20\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.7652 - accuracy: 0.7134 - val_loss: 0.7267 - val_accuracy: 0.7103\n",
            "Epoch 4/20\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7328 - val_loss: 0.6738 - val_accuracy: 0.7367\n",
            "Epoch 5/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6558 - accuracy: 0.7455 - val_loss: 0.6202 - val_accuracy: 0.7612\n",
            "Epoch 6/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6283 - accuracy: 0.7555 - val_loss: 0.6098 - val_accuracy: 0.7551\n",
            "Epoch 7/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6065 - accuracy: 0.7653 - val_loss: 0.5969 - val_accuracy: 0.7728\n",
            "Epoch 8/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5884 - accuracy: 0.7732 - val_loss: 0.5688 - val_accuracy: 0.7840\n",
            "Epoch 9/20\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.5679 - accuracy: 0.7844 - val_loss: 0.5510 - val_accuracy: 0.7942\n",
            "Epoch 10/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5499 - accuracy: 0.7927 - val_loss: 0.5323 - val_accuracy: 0.8021\n",
            "Epoch 11/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5332 - accuracy: 0.7979 - val_loss: 0.5456 - val_accuracy: 0.7896\n",
            "Epoch 12/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5169 - accuracy: 0.8062 - val_loss: 0.5174 - val_accuracy: 0.8038\n",
            "Epoch 13/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5023 - accuracy: 0.8112 - val_loss: 0.5090 - val_accuracy: 0.8002\n",
            "Epoch 14/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4883 - accuracy: 0.8180 - val_loss: 0.4844 - val_accuracy: 0.8138\n",
            "Epoch 15/20\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.4756 - accuracy: 0.8240 - val_loss: 0.4820 - val_accuracy: 0.8229\n",
            "Epoch 16/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4648 - accuracy: 0.8268 - val_loss: 0.5483 - val_accuracy: 0.7887\n",
            "Epoch 17/20\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.4560 - accuracy: 0.8317 - val_loss: 0.4732 - val_accuracy: 0.8235\n",
            "Epoch 18/20\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4470 - accuracy: 0.8347 - val_loss: 0.4730 - val_accuracy: 0.8153\n",
            "Epoch 19/20\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4390 - accuracy: 0.8380 - val_loss: 0.4347 - val_accuracy: 0.8373\n",
            "Epoch 20/20\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.4321 - accuracy: 0.8399 - val_loss: 0.4419 - val_accuracy: 0.8359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqoHe53h-SKd",
        "outputId": "97884434-f3b5-4131-b01a-bacd1592e155"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 6)        156       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " average_pooling2d_2 (Averag  (None, 14, 14, 6)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " average_pooling2d_3 (Averag  (None, 5, 5, 16)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 10,
        "id": "rvZvGGm6mBQv"
      },
      "source": [
        "While CNNs have fewer parameters,\n",
        "they can still be more expensive to compute\n",
        "than similarly deep MLPs\n",
        "because each parameter participates in many more\n",
        "multiplications.\n",
        "If you have access to a GPU, this might be a good time\n",
        "to put it into action to speed up training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 14,
        "id": "TXtW6909mBQw"
      },
      "source": [
        "We also need to [**update our training function to deal with GPUs.**]\n",
        "Unlike the `train_epoch_ch3` defined in :numref:`sec_softmax_scratch`,\n",
        "we now need to move each minibatch of data\n",
        "to our designated device (hopefully, the GPU)\n",
        "prior to making the forward and backward propagations.\n",
        "\n",
        "The training function `train_ch6` is also similar\n",
        "to `train_ch3` defined in :numref:`sec_softmax_scratch`.\n",
        "Since we will be implementing networks with many layers\n",
        "going forward, we will rely primarily on high-level APIs.\n",
        "The following training function assumes a model created from high-level APIs\n",
        "as input and is optimized accordingly.\n",
        "We initialize the model parameters\n",
        "on the device indicated by the `device` argument, using Xavier initialization as introduced in :numref:`subsec_xavier`.\n",
        "Just as with MLPs, our loss function is cross-entropy,\n",
        "and we minimize it via minibatch stochastic gradient descent.\n",
        "Since each epoch takes tens of seconds to run,\n",
        "we visualize the training loss more frequently.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 18,
        "id": "DmukZOj7mBQx"
      },
      "source": [
        "[**Now let us train and evaluate the LeNet-5 model.**]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "origin_pos": 19,
        "tab": [
          "tensorflow"
        ],
        "id": "GqZC5QLamBQx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rhn_YwGZrPYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RaGZY1vItuE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "acc = history.history[\"accuracy\"]\n",
        "epochs = range(1, 21)\n",
        "plt.plot(epochs, val_acc, \"b--\",\n",
        "         label=\"Validation loss\")\n",
        "plt.plot(epochs, acc, \"b\",\n",
        "         label=\"Training loss\")\n",
        "plt.title(\"Training and Validation Accuracies on Fashion MNIST\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3W831M8GwQGt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4803cb90-19f4-47b8-c8a9-9eb672a5d272"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "9qrYdOoctyF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e82ee5-1987-41b5-92e7-7117ca7c2a16"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4651 - accuracy: 0.8274\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.46509096026420593, 0.8274000287055969]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 20,
        "id": "aPeJcu_PmBQy"
      },
      "source": [
        "## Summary\n",
        "\n",
        "* A CNN is a network that employs convolutional layers.\n",
        "* In a CNN, we interleave convolutions, nonlinearities, and (often) pooling operations.\n",
        "* In a CNN, convolutional layers are typically arranged so that they gradually decrease the spatial resolution of the representations, while increasing the number of channels.\n",
        "* In traditional CNNs, the representations encoded by the convolutional blocks are processed by one or more fully-connected layers prior to emitting output.\n",
        "* LeNet was arguably the first successful deployment of such a network.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}