{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPSgir3gzL4H"
      },
      "source": [
        "**Notebook credit**: based on the original [here](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter10_dl-for-timeseries.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rMG_WqCzL4I"
      },
      "source": [
        "# Deep learning for timeseries\n",
        "\n",
        "- **timeseries**: any data obtained via measurements at regular intervals, like the daily price of a stock, the hourly electricity consumption of a city, or the weekly sales of a store\n",
        "- Timeseries are everywhere\n",
        "  - natural phenomena like seismic activity, the evolution of fish populations in a river, or the weather at a location\n",
        "  - human activity patterns like visitors to a website, a country’s GDP, or credit card transactions\n",
        "- Working with timeseries involves understanding the **dynamics** of a system\n",
        "  - its periodic cycles\n",
        "  - how it trends over time\n",
        "  - its regular regime\n",
        "  - its sudden spikes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmGVfrCtzL4I"
      },
      "source": [
        "## Different kinds of timeseries tasks\n",
        "\n",
        "- **Forecasting**: predicting what will happen next in a series\n",
        "  - Forecast electricity consumption a few hours in advance so you can anticipate demand\n",
        "  - forecast revenue a few months in advance so you can plan your budget\n",
        "  - forecast the weather a few days in advance so you can plan your schedule\n",
        "- **Classification**: Assign one or more categorical labels to a timeseries\n",
        "  - given the timeseries of the activity of a visitor on a website, classify whether the visitor is a bot or a human.\n",
        "- **Event detection**: Identify the occurrence of a specific expected event within a continuous data stream.\n",
        "  - A particularly useful application is “hotword detection,” where a model monitors an audio stream and detects utterances like \"Ok Google\" or \"Hey Siri\" or \"Alexa\"\n",
        "- **Anomaly detection**: Detect anything unusual happening within a continuous datastream.\n",
        "  - Unusual activity on your corporate network? Might be an attacker.\n",
        "  - Unusual readings on a manufacturing line? Time for a human to go take a look.\n",
        "  - Anomaly detection is typically done via unsupervised learning, because you often don’t know what kind of anomaly you’re looking for, so you can’t train on specific anomaly examples.\n",
        "\n",
        "We will focus on forecasting in this notebook. We'll learn about **recurrent neural networks (RNNs)** and how to apply them to **timeseries forecasting**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRHBmnsdzL4I"
      },
      "source": [
        "# A temperature-forecasting example\n",
        "\n",
        "- We will target a single problem: predicting the temperature 24 hours in the future\n",
        "- given a timeseries of hourly measurements of quantities such as atmospheric pressure and humidity, recorded by a set of sensors on the roof of a building\n",
        "- it’s a fairly challenging problem!\n",
        "- We’ll use this temperature-forecasting task to highlight what makes timeseries data fundamentally different from the kinds of datasets you’ve encountered so far\n",
        "- densely connected networks and convolutional networks aren’t well-equipped to deal with this kind of dataset\n",
        "- a different kind of machine learning technique—recurrent neural networks (RNNs)—really shines on this type of problem\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1YKGk9yBVex"
      },
      "source": [
        "## The Jena Dataset\n",
        "\n",
        "- weather timeseries dataset recorded at the weather station at the Max Planck Institute for Biogeochemistry in Jena, Germany\n",
        "- 14 different quantities (such as temperature, pressure, humidity, wind direction, and so on) were recorded every 10 minutes over several years\n",
        "- The original data goes back to 2003\n",
        "- but the subset of the data we’ll download is limited to 2009–2016.\n",
        "\n",
        "Let’s start by downloading and uncompressing the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh9_PAS4zL4I",
        "outputId": "1b87a7b5-4cfd-49d5-fc83-ed87fe3c801d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-29 15:43:16--  https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.194.224, 52.217.166.48, 54.231.236.0, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.194.224|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13565642 (13M) [application/zip]\n",
            "Saving to: ‘jena_climate_2009_2016.csv.zip.1’\n",
            "\n",
            "jena_climate_2009_2 100%[===================>]  12.94M  14.0MB/s    in 0.9s    \n",
            "\n",
            "2022-11-29 15:43:17 (14.0 MB/s) - ‘jena_climate_2009_2016.csv.zip.1’ saved [13565642/13565642]\n",
            "\n",
            "Archive:  jena_climate_2009_2016.csv.zip\n",
            "replace jena_climate_2009_2016.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: jena_climate_2009_2016.csv  \n",
            "replace __MACOSX/._jena_climate_2009_2016.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._jena_climate_2009_2016.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
        "!unzip jena_climate_2009_2016.csv.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFFcmq-fzL4J"
      },
      "source": [
        "**Inspecting the data of the Jena weather dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "N_XgKIt5zL4J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "fname = os.path.join(\"jena_climate_2009_2016.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(fname) as f:\n",
        "  data = f.read()"
      ],
      "metadata": {
        "id": "MLyACVgvEiaj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = data.split(\"\\n\")\n",
        "header = lines[0].split(\",\")\n",
        "lines = lines[1:]\n",
        "# print(header, len(lines))"
      ],
      "metadata": {
        "id": "b3kIembVEp6e"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGfY_zOYzL4K"
      },
      "source": [
        "**Parsing the data**\n",
        "\n",
        "- let us convert all 420,451 lines of data into NumPy arrays\n",
        "- one array for the year (extracted from Date Time)\n",
        "- one array for the temperature (in degrees Celsius)\n",
        "- one 2-d array for the rest of the data—the features we will use to predict future temperatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5sgV5JYdzL4K"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "temperature = np.zeros((len(lines), ))\n",
        "year = np.zeros((len(lines), ))\n",
        "\n",
        "raw_data = np.zeros((len(lines), len(header) - 1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, line in enumerate(lines):\n",
        "  year[i] = int(line.split(\",\")[0].split(\".\")[2].split(\" \")[0])\n",
        "  values = [float(x) for x in line.split(\",\")[1:]]\n",
        "  temperature[i] = values[1]\n",
        "  raw_data[i, :] = values[:]"
      ],
      "metadata": {
        "id": "bR4QD5CvF0CM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAagkBjwzL4K"
      },
      "source": [
        "**Plotting the temperature timeseries**\n",
        "\n",
        "- in the plot below, you can clearly see the yearly periodicity of temperature\n",
        "- the data spans 8 years"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "YQgpXwMOzL4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6007f32-b55c-4c52-ee53-a1493eff42cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(420451, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "raw_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "year.shape"
      ],
      "metadata": {
        "id": "7BwlsOJuIkN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e36a0c-a23c-4bad-fb4f-2b580230e37f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(420451,)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temperature.shape"
      ],
      "metadata": {
        "id": "oLXmLARCInmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8179b63c-8f2d-44ed-d585-c5f68a17886f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(420451,)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8imbzyHwzL4L"
      },
      "source": [
        "**Plotting the first 10 days of the temperature timeseries**\n",
        "\n",
        "- Plot below shows a more narrow plot of the first 10 days of temperature data\n",
        "- Because the data is recorded every 10 minutes, you get 24 × 6 = 144 data points per day"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(len(temperature)), temperature)"
      ],
      "metadata": {
        "id": "bGOeboq6Im65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "adde9cc7-6a5f-4868-adf1-dee852f49548"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7faa5d5d8d50>]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gFRPlwJDjnV"
      },
      "source": [
        "## Restricting to 2009 data\n",
        "\n",
        "Let us restrict ourselves to data from 2009 only for our models to train faster on free colab resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "xcF0Ow5qzL4L"
      },
      "outputs": [],
      "source": [
        "condition = (year == 2009)\n",
        "raw_data = raw_data[condition]\n",
        "temperature = temperature[condition]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "A9kOUaWC7zrb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "46bf38ab-17ff-42e5-fed8-f7d120fdbc5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7faa61ca1510>]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(range(len(temperature)), temperature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "0lOajRP08-Er",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0753b77b-dc1a-424b-8648-9d259cef8347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26278 13139 13139\n"
          ]
        }
      ],
      "source": [
        "num_train_samples = int(0.5 * len(raw_data))\n",
        "num_val_samples = int(0.25 * len(raw_data))\n",
        "num_test_samples = int(0.25 * len(raw_data))\n",
        "print(num_train_samples, num_test_samples, num_val_samples)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mjkL9etgLgrG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSy_TRIZzL4L"
      },
      "source": [
        "**Computing the number of samples we'll use for each data split**\n",
        "\n",
        "- we’ll use the first 50% of the data for training\n",
        "- the following 25% for validation\n",
        "- the last 25% for testing\n",
        "- When working with timeseries data, it’s important to use validation and test data that is more recent than the training data\n",
        "- because you’re trying to predict the future given the past, not the reverse\n",
        "- your validation/test splits should reflect that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "8umB7UpmzL4L"
      },
      "outputs": [],
      "source": [
        "mean = raw_data[:num_train_samples].mean(axis = 0)\n",
        "raw_data -= mean\n",
        "std = raw_data[:num_train_samples].std(axis = 0)\n",
        "raw_data /= std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZESBagezL4L"
      },
      "source": [
        "### Preparing the data\n",
        "\n",
        "The exact formulation of the problem will be as follows:\n",
        "\n",
        "**Given data covering the previous five days and sampled once per hour, can we predict the temperature 24 hours in advance?**\n",
        "\n",
        "- each timeseries in the data is on a different scale (for example, atmospheric pressure, measured in mbar, is around 1,000, while H2OC, measured in millimoles per mole, is around 3)\n",
        "- We’ll normalize each timeseries independently so that they all take small values on a similar scale\n",
        "- We’re going to use the first 26,278 timesteps as training data, so we’ll compute the mean and standard deviation only on this fraction of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DhKoAICzL4L"
      },
      "source": [
        "**Normalizing the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "a2vqHqSAzL4M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4oLaT0XF_Bh"
      },
      "source": [
        "- let’s create a `Dataset` object that yields batches of data from the past five days along with a target temperature 24 hours in the future\n",
        "- Because the samples in the dataset are highly redundant (sample $N$ and sample $N + 1$ will have most of their time-steps in common), it would be wasteful to explicitly allocate memory for every sample.\n",
        "- Instead, we’ll generate the samples on the fly while only keeping in memory the original `raw_data` and `temperature` arrays, and nothing more.\n",
        "- We could easily write a Python generator to do this, but there’s a built-in dataset utility in Keras that does just that\n",
        "- we can save ourselves some work by using `timeseries_dataset_from_array()`\n",
        "- You can generally use it for any kind of timeseries forecasting task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LgQjGEPH4HF"
      },
      "source": [
        "## Understanding `timeseries_dataset_from_array()`\n",
        "\n",
        "- The general idea is that you provide an array of timeseries data (the `data` argument), and `timeseries_dataset_from_array()` gives you windows extracted from the original timeseries (we’ll call them “sequences”)\n",
        "- For example, if you use `data = [0 1 2 3 4 5 6]` and `sequence_length=3`, then timeseries_dataset_from_array() will generate the following samples: `[0 1 2], [1 2 3], [2 3 4], [3 4 5], [4 5 6]`.\n",
        "- You can also pass a `targets` argument (an array) to `timeseries_dataset_ from_array()`\n",
        "  - The first entry of the targets array should match the desired target for the first sequence that will be generated from the data array.\n",
        "  - So if you’re doing timeseries forecasting, targets should be the same array as data, offset by some amount.\n",
        "- For instance, with `data=[0 1 2 3 4 5 6 ...]` and `sequence_length=3`, you could create a dataset to predict the next step in the series by passing `targets=[3 4 5 6 ...]`\n",
        "\n",
        "Let’s try it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Us6WiP1GzL4M"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "from tensorflow import keras\n",
        "int_sequence = np.arange(10)\n",
        "\n",
        "dummy_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    data = int_sequence[:-3],\n",
        "    targets = int_sequence[:3], \n",
        "    sequence_length = 3, \n",
        "    batch_size = 2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in dummy_dataset:\n",
        "  for i in range(inputs.shape[0]):\n",
        "    print([int(x) for x in inputs[i]], int(targets[i]))"
      ],
      "metadata": {
        "id": "V1UakX76NRLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f914c831-228e-456f-c105-62f0eb2f12a8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2] 0\n",
            "[1, 2, 3] 1\n",
            "[2, 3, 4] 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSggE6PkzL4M"
      },
      "source": [
        "**Instantiating datasets for training, validation, and testing**\n",
        "\n",
        "- We’ll use `timeseries_dataset_from_array()` to instantiate three datasets:\n",
        "  - one for training, one for validation, and one for testing.\n",
        "- We’ll use the following parameter values:\n",
        "  - `sampling_rate = 6`: Observations will be sampled at one data point per hour: we will only keep one data point out of 6.\n",
        " - `sequence_length = 120`: Observations will go back 5 days (120 hours)\n",
        " - `delay = sampling_rate * (sequence_length + 24 - 1)`: The target for a sequence will be the temperature 24 hours after the end of the sequence.\n",
        "- When making the training dataset, we’ll pass `start_index = 0` and `end_index = num_train_samples` to only use the first 50% of the data.\n",
        "- For the validation dataset, we’ll pass `start_index = num_train_samples` and `end_index = num_train_samples + num_val_samples` to use the next 25% of the data.\n",
        "- Finally, for the test dataset, we’ll pass `start_index=num_train_samples+num_val_samples` to use the remaining samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "c1eijnuXzL4M"
      },
      "outputs": [],
      "source": [
        "sampling_rate = 6\n",
        "sequence_length = 120 \n",
        "delay = sampling_rate * (sequence_length + 24 - 1)\n",
        "batch_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay], \n",
        "    targets = temperature[delay:],\n",
        "    sampling_rate = sampling_rate, \n",
        "    sequence_length = sequence_length, \n",
        "    shuffle = True, \n",
        "    start_index = 0, \n",
        "    end_index = num_train_samples\n",
        ")"
      ],
      "metadata": {
        "id": "j5pJ_t2OOlsY"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True, # randomly shuffle the output samples instead of drawing them in chronological order\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples,\n",
        "    end_index=num_train_samples + num_val_samples\n",
        ")"
      ],
      "metadata": {
        "id": "agPoV-zGPelW"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    raw_data[:-delay],\n",
        "    targets=temperature[delay:],\n",
        "    sampling_rate=sampling_rate,\n",
        "    sequence_length=sequence_length,\n",
        "    shuffle=True, # randomly shuffle the output samples instead of drawing them in chronological order\n",
        "    batch_size=batch_size,\n",
        "    start_index=num_train_samples + num_val_samples\n",
        ")"
      ],
      "metadata": {
        "id": "SjPIyNFTPvEU"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4o-8lT4zL4N"
      },
      "source": [
        "**Inspecting the output of one of our datasets**\n",
        "\n",
        "- Each dataset yields a tuple `(samples, targets)`, where\n",
        "  - `samples` is a batch of 256 samples, each containing 120 consecutive hours of input data\n",
        "  - `targets` is the corre-sponding array of 256 target temperatures\n",
        "  \n",
        "Note that because we used `shuffle=True`, the samples are randomly shuffled, so two consecutive sequences in a batch (like `samples[0]` and `samples[1]`) aren’t necessarily temporally close."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "2vMMjOE0zL4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afc0f137-6a23-4c31-ff97-24b8e22667be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "samples shape (128, 120, 14)\n",
            "targets shape (128,)\n"
          ]
        }
      ],
      "source": [
        "for samples, targets in train_dataset:\n",
        "  print(\"samples shape\", samples.shape)\n",
        "  print(\"targets shape\", targets.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqjY8hFYzL4N"
      },
      "source": [
        "## A common-sense, non-machine-learning baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM2EADEczL4N"
      },
      "source": [
        "**Computing the common-sense baseline MAE**\n",
        "\n",
        "\n",
        "- Before we start using deep learning, let’s try a simple, common-sense approach.\n",
        "- Such common-sense base- lines can be useful when you’re approaching a new problem for which there is no known solution (yet).\n",
        "- A classic example is that of unbalanced classification tasks, where some classes are much more common than others.\n",
        "- If your dataset contains 90% instances of class A and 10% instances of class B, then a common-sense approach to the classification task is to always predict “A” when presented with a new sample.\n",
        "- Such a classifier is 90% accurate overall, and any learning-based approach should therefore beat this 90% score in order to demonstrate usefulness\n",
        "- **Sometimes, such elementary baselines can prove surprisingly hard to beat.**\n",
        "- In this case, a common-sense approach is to always predict that the temperature 24 hours from now will be equal to the temperature right now. Let’s evaluate this approach, using the mean absolute error (MAE) metric, defined as follows:\n",
        "```\n",
        "np.mean(np.abs(preds - targets))\n",
        "```\n",
        "Here’s the evaluation loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "FgysIgVmzL4N"
      },
      "outputs": [],
      "source": [
        "def evaluate_naive_method(dataset):\n",
        "  total_abs_err = 0 \n",
        "  samples_seen = 0 \n",
        "  for samples, targets in dataset:\n",
        "    preds = samples[:, -1, 1] * std[1] + mean[1]\n",
        "    total_abs_err  += np.sum(np.abs(preds - targets))\n",
        "    samples_seen += samples.shape[0]\n",
        "  return total_abs_err / samples_seen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validate MAE: {evaluate_naive_method(val_dataset):.2f}\")\n",
        "print(f\"Validate MAE: {evaluate_naive_method(test_dataset):.2f}\")"
      ],
      "metadata": {
        "id": "5z1Rh5CISLAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b5c1c0-b6ba-4b7a-ee28-9768646ca54c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validate MAE: 2.68\n",
            "Validate MAE: 2.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foL3GXI0YXh0"
      },
      "source": [
        "- common-sense baseline achieves:\n",
        "  - a validation MAE of 2.68 degrees Celsius\n",
        "  - a test MAE of 2.59 degrees Celsius\n",
        "- So, if you always assume that the temperature 24 hours in the future will be the same as it is now, you will be off by two and a half degrees on average.\n",
        "- It’s not too bad, but you probably won’t launch a weather forecasting service based on this heuristic!\n",
        "- Let's see if we can use deep learning to do better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUsuHmlYzL4N"
      },
      "source": [
        "## Let's try a basic machine-learning model\n",
        "\n",
        "- it’s useful to establish a common-sense baseline before trying machine learning approaches\n",
        "- similarly, it’s useful to try simple, cheap machine learning models (such as small, densely connected networks) before looking into complicated and computationally expensive models such as RNNs\n",
        "- This is the best way to make sure any further complexity you throw at the problem is legitimate and delivers real benefits.\n",
        "- The following listing shows a fully connected model that starts by flattening the data and then runs it through two Dense layers.\n",
        "- Note the lack of an activation function on the last Dense layer, which is typical for a regression problem.\n",
        "- We use mean squared error (MSE) as the loss, rather than MAE, because unlike MAE, it’s smooth around zero, which is a useful property for gradient descent.\n",
        "- We will monitor MAE by adding it as a metric in `compile()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsaBdduczL4O"
      },
      "source": [
        "**Training and evaluating a densely connected model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "KJKltBaEzL4O"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape = (sequence_length, raw_data.shape[-1]))\n",
        "\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(16, activation = 'relu')(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "RR-4XNuYTFw8"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint('jena_dense.keras', save_best_only = True)\n",
        "]"
      ],
      "metadata": {
        "id": "eLtC4XEqTW4O"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])\n",
        "history = model.fit(train_dataset, epochs = 5, validation_data = val_dataset, callbacks = callbacks)"
      ],
      "metadata": {
        "id": "7JqRutknTipP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6554b22-fd1c-4ada-cb2a-fd0dc705311d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "200/200 [==============================] - 7s 32ms/step - loss: 13.4661 - mae: 2.7559 - val_loss: 30.5675 - val_mae: 4.6218\n",
            "Epoch 2/5\n",
            "200/200 [==============================] - 7s 33ms/step - loss: 6.3322 - mae: 1.9573 - val_loss: 18.8479 - val_mae: 3.4862\n",
            "Epoch 3/5\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 5.0311 - mae: 1.7418 - val_loss: 16.4847 - val_mae: 3.2299\n",
            "Epoch 4/5\n",
            "200/200 [==============================] - 10s 49ms/step - loss: 4.2139 - mae: 1.5869 - val_loss: 16.4901 - val_mae: 3.2040\n",
            "Epoch 5/5\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 3.7079 - mae: 1.4920 - val_loss: 19.6638 - val_mae: 3.6024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('jena_dense.keras')\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "id": "pI-YjM76UJMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6876f30a-4725-4c84-b16e-8f81f1902d49"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 2s 35ms/step - loss: 25.9692 - mae: 3.7594\n",
            "Test MAE: 3.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8KdgUQOzL4O"
      },
      "source": [
        "**Plotting results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "C8jDePPRzL4O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "606fd305-4d22-4bd8-98c5-5a6eacef4c06"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['mae']\n",
        "val_loss = history.history['val_mae']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label = 'Training MAE')\n",
        "plt.plot(epochs, val_loss, 'ro', label = 'Validationn MAE')\n",
        "plt.title('Training and valdation MAE')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH08_j0Jb9Si"
      },
      "source": [
        "- Validation losses are worse than the no-learning baseline\n",
        "- This goes to show the merit of having this baseline in the first place: it turns out to be not easy to outperform\n",
        "- common sense contains a lot of valuable information to which a machine learning model doesn’t have access\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6w_6ug4cHke"
      },
      "source": [
        "### How can dense network do worse than simple base line?\n",
        "\n",
        "- if a simple, well-performing model exists to go from the data to the targets (the common-sense baseline), why doesn’t the model we’re training find it and improve on it?\n",
        "- the space of models in which you’re searching for a solution— that is, your *hypothesis space*—is the space of all possible two-layer networks with the configuration you defined.\n",
        "- The common-sense heuristic is just one model among millions that can be represented in this space\n",
        "- It’s like looking for a needle in a haystack.\n",
        "- **Just because a good solution technically exists in your hypothesis space doesn’t mean you’ll be able to find it via gradient descent.**\n",
        "- That’s a pretty significant limitation of machine learning in general\n",
        "- unless the learning algorithm is hardcoded to look for a specific kind of simple model, it can sometimes fail to find a simple solution to a simple problem\n",
        "- That’s why leveraging good feature engineering and relevant architecture priors is essential: you need to precisely tell your model what it should be looking for."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uW1gBdYzL4O"
      },
      "source": [
        "## Let's try a 1D convolutional model\n",
        "\n",
        "- You already know about the `Conv2D` layers, which see their inputs through small windows that swipe across 2D grids.\n",
        "- There are also 1D and even 3D versions of these layers: `Conv1D` and `Conv3D`.\n",
        "- The `Conv1D` layer relies on 1D windows that slide across input sequences, and the `Conv3D` layer relies on cubic windows that slide across input volumes.\n",
        "- You can thus build 1D convnets, strictly analogous to 2D convnets.\n",
        "- They’re a great fit for any sequence data that follows the translation invariance assumption (meaning that if you slide a window over the sequence, the content of the window should follow the same properties independently of the location of the window).\n",
        "- Let’s try one on our temperature-forecasting problem.\n",
        "- We’ll pick an initial window length of 24, so that we look at 24 hours of data at a time (one cycle).\n",
        "- As we downsample the sequences (via `MaxPooling1D` layers), we’ll reduce the window size accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "FMZAhz8OzL4O"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape = (sequence_length, raw_data.shape[-1]))\n",
        "x = layers.Conv1D(8, 24, activation = 'relu')(inputs)\n",
        "x = layers.MaxPooling1D(2)(x)\n",
        "x = layers.Conv1D(8, 12, activation = 'relu')(x)\n",
        "x = layers.MaxPooling1D(2)(x)\n",
        "x = layers.Conv1D(8, 6, activation = 'relu')(x)\n",
        "x = layers.MaxPooling1D(2)(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint('jena_conv.keras', save_best_only=True)\n",
        "]"
      ],
      "metadata": {
        "id": "uYhfxKTGWNcG"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])\n",
        "history = model.fit(train_dataset, epochs = 5, validation_data = val_dataset, callbacks = callbacks)"
      ],
      "metadata": {
        "id": "axdkpz1dWS-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659b976d-460e-4561-a31c-c6bed5efa17e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "200/200 [==============================] - 12s 55ms/step - loss: 22.2547 - mae: 3.6230 - val_loss: 33.3971 - val_mae: 4.5853\n",
            "Epoch 2/5\n",
            "200/200 [==============================] - 14s 68ms/step - loss: 16.0868 - mae: 3.1148 - val_loss: 38.6853 - val_mae: 4.9625\n",
            "Epoch 3/5\n",
            "200/200 [==============================] - 19s 92ms/step - loss: 14.7031 - mae: 2.9500 - val_loss: 50.4763 - val_mae: 5.7238\n",
            "Epoch 4/5\n",
            "200/200 [==============================] - 12s 60ms/step - loss: 13.8725 - mae: 2.8700 - val_loss: 49.1534 - val_mae: 5.6488\n",
            "Epoch 5/5\n",
            "200/200 [==============================] - 16s 77ms/step - loss: 13.3161 - mae: 2.8114 - val_loss: 32.9984 - val_mae: 4.5968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('jena_conv.keras')\n",
        "print(f\"Test MAE:  {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "id": "-qf_BYNFWpXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4bcfa42-031c-427a-e632-4cf19affc621"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 4s 78ms/step - loss: 37.4708 - mae: 4.7176\n",
            "Test MAE:  4.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj6DSptweTOP"
      },
      "source": [
        "**The 1D convolution model performs even worse than the densely connected one**\n",
        "\n",
        "Test MAE is higher than 4 degrees, far from the common-sense baseline. What went wrong here? Two things:\n",
        "- First, weather data doesn’t quite respect the translation invariance assumption. While the data does feature daily cycles, data from a morning follows different properties than data from an evening or from the middle of the night. Weather data is only translation-invariant for a very specific timescale.\n",
        "- Second, order in our data matters—a lot. The recent past is far more informa- tive for predicting the next day’s temperature than data from five days ago. A 1D convnet is not able to leverage this fact. **In particular, our max pooling and global average pooling layers are largely destroying order information.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqHsZ2ErzL4O"
      },
      "source": [
        "## A first recurrent baseline\n",
        "\n",
        "- The densely connected approach first flattened the timeseries, which removed the notion of time from the input data.\n",
        "- The convolutional approach treated every segment of the data in the same way, even applying pooling, which destroyed order information.\n",
        "- Let’s instead look at the data as what it is: **a sequence, where causality and order matter.**\n",
        "- There’s a family of neural network architectures designed specifically for this use case: **recurrent neural networks**.\n",
        "- Among them, the **Long Short Term Memory (LSTM)** layer has long been very popular.\n",
        "- We’ll see in a minute how these models work, but let’s start by giving the LSTM layer a try."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHnw-ilBzL4O"
      },
      "source": [
        "**A simple LSTM-based model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "BtMNHqAmzL4P"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape = (sequence_length, raw_data.shape[-1]))\n",
        "x = layers.LSTM(16)(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint('jena_lstm.keras', save_best_only = True)\n",
        "]"
      ],
      "metadata": {
        "id": "NJkxKdMqXoUT"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "history = model.fit(train_dataset, epochs = 5, validation_data = val_dataset, callbacks = callbacks)"
      ],
      "metadata": {
        "id": "mAQ_KM84Xtq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b36b83b9-7036-4ec5-91b2-ae51b07da042"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "200/200 [==============================] - 18s 78ms/step - loss: 69.2562 - mae: 6.5238 - val_loss: 129.5052 - val_mae: 10.2527\n",
            "Epoch 2/5\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 34.2342 - mae: 4.3729 - val_loss: 73.0390 - val_mae: 7.1517\n",
            "Epoch 3/5\n",
            "200/200 [==============================] - 16s 78ms/step - loss: 19.3517 - mae: 3.2672 - val_loss: 38.8106 - val_mae: 4.8233\n",
            "Epoch 4/5\n",
            "200/200 [==============================] - 17s 83ms/step - loss: 12.3163 - mae: 2.6320 - val_loss: 21.8626 - val_mae: 3.5252\n",
            "Epoch 5/5\n",
            "200/200 [==============================] - 15s 76ms/step - loss: 9.7582 - mae: 2.3644 - val_loss: 16.0485 - val_mae: 3.0414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('jena_lstm.keras')\n",
        "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
      ],
      "metadata": {
        "id": "ZEUdtjY8X3oN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e3a79d-bae5-428e-aa3b-de6751704559"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 3s 51ms/step - loss: 13.5830 - mae: 2.8509\n",
            "Test MAE: 2.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN2CA2g2fLHe"
      },
      "source": [
        "We achieve a test MAE of about 2.8 degrees. The LSTM-based model didn't beat the common-sense baseline but it did much better than other deep learning models.\n",
        "\n",
        "- Why did the LSTM model perform markedly better than the densely connected one or the convnet?\n",
        "- And how can we further refine the model?\n",
        "- To answer this, we will take a closer look at recurrent neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow0Qrx2_zL4P"
      },
      "source": [
        "# Understanding recurrent neural networks\n",
        "\n",
        "\n",
        "- all neural networks you’ve seen so far, such as densely connected networks and convnets, have **no memory**.\n",
        "- Each input shown to them is processed independently, with no **state** kept between inputs.\n",
        "- With such networks, in order to process a sequence or a temporal series of data points, you have to show the entire sequence to the network at once: turn it into a single data point.\n",
        "  - For instance, this is what we did in the densely connected network example: we flattened our five days of data into a single large vector and processed it in one go.\n",
        "  - Such networks are called **feedforward networks**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zomxzQ7A66rR"
      },
      "source": [
        "- Think about how we read text\n",
        "- We process it word by word—or rather, eye saccade by eye saccade—while keeping memories of what came before\n",
        "- this gives you a fluid representation of the meaning conveyed by this sentence.\n",
        "- Biological intelligence processes information incrementally while maintaining an internal model of what it’s processing, built from past information and constantly updated as new information comes in.\n",
        "- A recurrent neural network (RNN) adopts the same principle, albeit in an extremely simplified version:\n",
        "  - it processes sequences by iterating through the sequence elements and maintaining a state that contains information relative to what it has seen so far.\n",
        "  - In effect, an RNN is a type of neural network that has an internal loop (see figure below).\n",
        "\n",
        "<img src=\"https://github.com/ambujtewari/stats315-winter2022/raw/main/images/RNN.png\" width=\"400\">\n",
        "\n",
        "- state of the RNN is reset between processing two different, independent sequences (such as two samples in a batch)\n",
        "- so you still consider one sequence to be a single data point: a single input to the network.\n",
        "- What changes is that this data point is no longer processed in a single step; rather, the network internally loops over sequence elements.\n",
        "\n",
        "\n",
        "To make these notions of *loop* and *state* clear, let’s implement the forward pass of a toy RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXADfdp3zL4P"
      },
      "source": [
        "**NumPy implementation of a simple RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "h471XI6RzL4P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "timesteps = 100 \n",
        "input_features = 32 \n",
        "output_features = 64"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.random.random((timesteps, input_features))\n",
        "\n",
        "state_t = np.zeros((output_features,))\n",
        "\n",
        "W = np.random.random((output_features, input_features))\n",
        "U = np.random.random((output_features, output_features))\n",
        "b = np.random.random((output_features,))\n",
        "\n",
        "sucessive_outputs = []\n",
        "\n",
        "for input_t in inputs:\n",
        "  output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
        "  sucessive_outputs.append(output_t)\n",
        "\n",
        "  state_t = output_t\n",
        "\n",
        "final_output_sequence = np.stack(sucessive_outputs, axis = 0)\n"
      ],
      "metadata": {
        "id": "ua1zFP77-Fkw"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZfnKwNvCned"
      },
      "source": [
        "- In this example, the final output is a rank-2 tensor of shape `(timesteps,output_features)`, where each timestep is the output of the loop at time t.\n",
        "- Each timestep `t` in the output tensor contains information about timesteps `0` to `t` in the input sequence—about the entire past.\n",
        "- For this reason, in many cases, you don’t need this full sequence of outputs; you just need the last output (`output_t` at the end of the loop), because it already contains information about the entire sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2dQwNR7zL4P"
      },
      "source": [
        "### A recurrent layer in Keras\n",
        "\n",
        "- The process we just naively implemented in NumPy corresponds to an actual Keras layer—the `SimpleRNN` layer.\n",
        "- There is one minor difference: `SimpleRNN` processes **batches** of sequences, like all other Keras layers, not a single sequence as in the NumPy example.\n",
        "- This means it takes inputs of shape `(batch_size, timesteps, input_features)`, rather than `(timesteps, input_features)`.\n",
        "- When specifying the shape argument of the initial `Input()`, note that you can set the timesteps entry to `None`, which enables your network to process sequences of arbitrary length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCa8acubzL4P"
      },
      "source": [
        "**An RNN layer that can process sequences of any length**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "AKAjcc1FzL4P"
      },
      "outputs": [],
      "source": [
        "num_features = 14\n",
        "inputs = keras.Input(shape = (None, num_features))\n",
        "outputs = layers.SimpleRNN(16)(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvyfc-wIEnsa"
      },
      "source": [
        "- This is especially useful if your model is meant to process sequences of variable length.\n",
        "- However, if all of your sequences have the same length, it is recommended that you specify a complete input shape\n",
        "  - it enables `model.summary()` to display output length information, which is always nice\n",
        "  - it can unlock some performance optimizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubhMHgKWFQZf"
      },
      "source": [
        "- All recurrent layers in Keras (`SimpleRNN`, `LSTM`, and `GRU`) can be run in two different modes:\n",
        "  - they can return either full sequences of successive outputs for each timestep (a rank-3 tensor of shape `(batch_size, timesteps, output_features)`), or\n",
        "  - return only the last output for each input sequence (a rank-2 tensor of shape `(batch_ size, output_features)`).\n",
        "- These two modes are controlled by the `return_sequences` constructor argument.\n",
        "- Let’s look at an example that uses `SimpleRNN` and returns only the output at the last timestep.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTbBsWl6zL4P"
      },
      "source": [
        "**An RNN layer that returns only its last output step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Gh3zKb1DzL4Q"
      },
      "outputs": [],
      "source": [
        "num_features = 14 \n",
        "steps = 120\n",
        "inputs = keras.Input(shape = (steps, num_features))\n",
        "outputs = layers.SimpleRNN(16, return_sequences = False)(inputs)\n",
        "# return_sequences = false is the default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT4ajnMXGIWI"
      },
      "source": [
        "The following example returns the full state sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oocWCr-TzL4Q"
      },
      "source": [
        "**An RNN layer that returns its full output sequence**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "bFYT_6dgzL4Q"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape = (steps, num_features))\n",
        "\n",
        "x = layers.SimpleRNN(16, return_sequences = True)(inputs)\n",
        "x = layers.SimpleRNN(16, return_sequences = True)(x)\n",
        "outputs = layers.SimpleRNN(16)(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eLvDZXGGQkd"
      },
      "source": [
        "- It’s sometimes useful to stack several recurrent layers one after the other in order to increase the representational power of a network.\n",
        "- In such a setup, you have to get all of the intermediate layers to return a full sequence of outputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2c4qOljzL4Q"
      },
      "source": [
        "**Stacking RNN layers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "5t6eeCa2zL4Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yni2hB29SLNN"
      },
      "source": [
        "### LSTM layers\n",
        "\n",
        "- `SimpleRNN` layer is generally too simplistic to be of real use.\n",
        "- major issue: although it should theoretically be able to retain at time `t` information about inputs seen many timesteps before, such long-term dependencies prove impossible to learn in practice.\n",
        "- This is due to the **vanishing gradient problem**, an effect that is similar to what is observed with non-recurrent networks (feedforward networks) that are many layers deep:\n",
        "  - as you keep adding layers to a network, the network eventually becomes untrainable.\n",
        "- `LSTM` and `GRU` were designed to address these issues.\n",
        "\n",
        "Let’s consider the LSTM layer. The underlying Long Short-Term Memory (LSTM) algorithm was developed by [Hochreiter and Schmidhuber in 1997](https://doi.org/10.1162/neco.1997.9.8.1735); it was the culmi- nation of their research on the vanishing gradient problem.\n",
        "\n",
        "\n",
        "- This layer is a variant of the `SimpleRNN` layer you already know about\n",
        "- it adds a way to carry information across many timesteps\n",
        "- Imagine a conveyor belt running parallel to the sequence you’re processing\n",
        "  - Information from the sequence can jump onto the conveyor belt at any point,\n",
        "  - be transported to a later timestep, and\n",
        "  - jump off, intact, when you need it.\n",
        "- This is essentially what LSTM does: it saves information for later, thus preventing older signals from gradually vanishing during processing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTqa4oTmTlmg"
      },
      "source": [
        "**Understanding LSTMs pictorially**\n",
        "\n",
        "- let’s start from the SimpleRNN cell (see figure 10.8).\n",
        "- Because you’ll have a lot of weight matrices, index the `W` and `U` matrices in the cell, with the letter `o` (`Wo` and `Uo`) for *output*.\n",
        "\n",
        "<img src=\"https://github.com/ambujtewari/stats315-winter2022/raw/main/images/starting_point_LSTM.png\" height=\"400\">\n",
        "\n",
        "\n",
        "\n",
        "- Let’s add an additional data flow that carries information across time- steps.\n",
        "- Call its values at different timesteps `c_t`, where C stands for *carry*.\n",
        "- This information will have the following impact on the cell:\n",
        "  - it will be combined with the input connection and the recurrent connection (via a dense transformation: a dot product with a weight matrix followed by a bias add and the application of an activation function), and\n",
        "  - it will affect the state being sent to the next timestep (via an activation function and a multiplication operation).\n",
        "- Conceptually, the carry dataflow is a way to modulate the next output and the next state (see figure 10.9)\n",
        "\n",
        "<img src=\"https://github.com/ambujtewari/stats315-winter2022/raw/main/images/SimpleRNN_to_LSTM.png\" height=\"400\">\n",
        "\n",
        "- Now the subtlety—the way the next value of the carry dataflow is computed\n",
        "- It involves three distinct transformations.\n",
        "- All three have the form of a SimpleRNN cell:\n",
        "```\n",
        "y = activation(dot(state_t, U) + dot(input_t, W) + b)\n",
        "```\n",
        "- But all three transformations have their own weight matrices, which we’ll index with the letters `i`, `f`, and `k`. Here’s what we have so far (it may seem a bit arbitrary, but hang on for a moment!).\n",
        "```\n",
        "output_t = activation(dot(state_t, Uo) + dot(input_t, Wo) + dot(c_t, Vo) + bo)\n",
        "i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)\n",
        "f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf)\n",
        "k_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)\n",
        "```\n",
        "-We obtain the new carry state (the next `c_t`) by combining `i_t`, `f_t`, and `k_t`.\n",
        "```\n",
        "c_t+1 = i_t * k_t + c_t * f_t\n",
        "```\n",
        "- Add this as shown in figure 10.10, and that’s it.\n",
        "- Not so complicated—merely a tad complex.\n",
        "\n",
        "<img src=\"https://github.com/ambujtewari/stats315-winter2022/raw/main/images/anatomy_LSTM.png\" height=\"400\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykktVoQHVstm"
      },
      "source": [
        "**Interpreting LSTM operations**\n",
        "\n",
        "- you can interpret what each of these operations is meant to do.\n",
        "- For instance, you can say that multiplying `c_t` and `f_t` is a way to deliberately **forget** irrelevant information in the carry dataflow.\n",
        "- Meanwhile, `i_t` and `k_t` provide information about the present, updating the carry track with new information.\n",
        "- But at the end of the day, these interpretations don’t mean much, because what these operations actually do is determined by the contents of the weights parameterizing them\n",
        "  - the weights are learned in an end-to-end fashion, starting over with each training round, making it impossible to credit this or that operation with a specific purpose.\n",
        "- The specification of an RNN cell (as just described) determines your hypothesis space—the space in which you’ll search for a good model configuration during training\n",
        "- but it doesn’t determine what the cell does; that is up to the cell weights.\n",
        "- The same cell with different weights can be doing very different things.\n",
        "- So the combination of operations making up an RNN cell is better interpreted as **a set of constraints on your search**, not as a design in an engineering sense.\n",
        "- Arguably, the choice of such constraints—the question of how to implement RNN cells—is better left to optimization algorithms (like genetic algorithms or reinforcement- learning processes) than to human engineers.\n",
        "  - In the future, that’s how we’ll build our models.\n",
        "- In summary: you don’t need to understand anything about the specific archi- tecture of an LSTM cell; as a human, it shouldn’t be your job to understand it.\n",
        "- Just keep in mind what the LSTM cell is meant to do: allow past information to be reinjected at a later time, thus fighting the vanishing-gradient problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ8sSpFmzL4Q"
      },
      "source": [
        "# Advanced use of recurrent neural networks\n",
        "\n",
        "We’ll cover the following:\n",
        "- *Recurrent dropout*—This is a variant of dropout, used to fight overfitting in recurrent layers.\n",
        "- *Stacking recurrent layers*—This increases the representational power of the model (at the cost of higher computational loads).\n",
        "- *Bidirectional recurrent layers*—These present the same information to a recurrent network in different ways, increasing accuracy and mitigating forgetting issues.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3HEgIvgzL4Q"
      },
      "source": [
        "### Using recurrent dropout to fight overfitting\n",
        "\n",
        "\n",
        "- You’re already familiar with a classic technique for fighting overfitting: dropout\n",
        "- It randomly zeros out input units of a layer in order to break happenstance correlations in the training data that the layer is exposed to.\n",
        "- But how to correctly apply dropout in recurrent networks isn’t a trivial question.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wblgb9qJ-Sy8"
      },
      "source": [
        "**Recurrent dropout**\n",
        "\n",
        "- It has long been known that applying dropout before a recurrent layer hinders learning rather than helping with regularization.\n",
        "- In 2016, Yarin Gal, as part of his PhD thesis on Bayesian deep learning, determined the proper way to use dropout with a recurrent network\n",
        "- the same dropout mask (the same pattern of dropped units) should be applied at every timestep, instead of using a dropout mask that varies randomly from timestep to timestep.\n",
        "- in order to regularize the representations formed by the recurrent gates of layers such as GRU and LSTM, a temporally constant dropout mask should be applied to the inner recurrent activations of the layer (a recurrent dropout mask)\n",
        "- Using the same dropout mask at every timestep allows the network to properly propagate its learning error through time; a temporally random dropout mask would disrupt this error signal and be harmful to the learning process.\n",
        "- Every recurrent layer in Keras has two dropout-related arguments:\n",
        "  - `dropout`, a float specifying the dropout rate for input units of the layer, and\n",
        "  - `recurrent_dropout`, specifying the dropout rate of the recurrent units. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0Eij8Tj_N47"
      },
      "source": [
        "**Adding recurrent dropout to our first LSTM example**\n",
        "\n",
        "- Let’s add recurrent dropout to the LSTM layer of our first LSTM example and see how doing so impacts overfitting.\n",
        "- Thanks to dropout, we won’t need to rely as much on network size for regularization, so we can use an LSTM layer with twice as many units, which should, hopefully, be more expressive\n",
        "  - without dropout, this network would have started overfitting right away—try it\n",
        "- Because networks being regularized with dropout always take much longer to fully converge, we need to train the model longer. The performance below isn't as good because we're only running 10 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXD07OLLzL4Q"
      },
      "source": [
        "**Training and evaluating a dropout-regularized LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "RvPd7uzXzL4Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "D3faHm1-tfAC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaGPjGL1zL4R"
      },
      "source": [
        "### Stacking recurrent layers\n",
        "\n",
        "- Increasing network capacity is typically done by increasing the number of units in the layers or adding more layers.\n",
        "- **Recurrent layer stacking** is a classic way to build more-powerful recurrent networks:\n",
        "  - for instance, not too long ago the Google Translate algorithm was powered by a stack of seven large LSTM layers—that’s huge.\n",
        "- To stack recurrent layers on top of each other in Keras, all intermediate layers should return their full sequence of outputs (a rank-3 tensor) rather than their output at the last timestep.\n",
        "  - As you’ve already learned, this is done by specifying `return_sequences=True`.\n",
        "- we’ll try a stack of two dropout-regularized recurrent layers.\n",
        "- For a change, we’ll use Gated Recurrent Unit (GRU) layers instead of LSTM.\n",
        "- GRU is very similar to LSTM—you can think of it as a slightly simpler, streamlined version of the LSTM architecture.\n",
        "  - It was introduced in 2014 by [Cho et al.](https://arxiv.org/abs/1409.1259) when recurrent networks were just starting to gain interest anew"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCbb8vArzL4R"
      },
      "source": [
        "**Training and evaluating a dropout-regularized, stacked GRU model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "MlS8GGogzL4R"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape = (sequence_length, raw_data.shape[-1]))\n",
        "\n",
        "# what is the drop out rate within recurrent relationship? ensure we drop out the same thing over time \n",
        "x = layers.LSTM(32, recurrent_dropout = 0.25)(inputs)\n",
        "# regularizing the dense layer after this \n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape = (sequence_length, raw_data.shape[-1]))\n",
        "x = layers.GRU(32, recurrent_dropout = 0.5, return_sequences = True)(inputs)\n",
        "x = layers.GRU(32, recurrent_dropout = 0.5)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "NGoR5YnKEA8I"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint('jena_lstm_dropout.keras', save_best_only = True)\n",
        "]\n",
        "\n",
        "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "history = model.fit(train_dataset, epochs = 2, validation_data = val_dataset, callbacks = callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyNQT-TqJMxU",
        "outputId": "b0c6dd1c-014e-4e24-877e-25c90c471657"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "200/200 [==============================] - 58s 266ms/step - loss: 34.3836 - mae: 4.4137 - val_loss: 40.0225 - val_mae: 4.9305\n",
            "Epoch 2/2\n",
            "200/200 [==============================] - 52s 260ms/step - loss: 14.8493 - mae: 2.9665 - val_loss: 19.3685 - val_mae: 3.3301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['mae']"
      ],
      "metadata": {
        "id": "ZB0pm0_JJlNg"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.model.load_model('jena_stacked_gru_dropout.keras')\n",
        "print(f\"test mae: {model.evaluate(test_dataset[1])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "i7imetN3Dx3A",
        "outputId": "4d7a2a62-1e4d-40a3-d286-035c6d24c5ef"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-3ffe45dec407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jena_stacked_gru_dropout.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"test mae: {model.evaluate(test_dataset[1])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras' has no attribute 'model'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnvI5At0DEJ5"
      },
      "source": [
        "We achieve a test MAE of 2.7 which is better than what vanilla LSTM gave us. It's still slightly higher than the test MAE of the non-ML baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq3E_49hzL4R"
      },
      "source": [
        "### Using bidirectional RNNs\n",
        "\n",
        "- RNNs are notably order-dependent: they process the timesteps of their input sequences in order, and shuffling or reversing the timesteps can completely change the representations the RNN extracts from the sequence.\n",
        "- This is precisely the reason they perform well on problems where order is meaningful, such as the temperature-forecasting problem.\n",
        "- A bidirectional RNN exploits the order sensitivity of RNNs: it uses two regular RNNs, such as the GRU and LSTM layers you’re already familiar with, each of which processes the input sequence in one direction (chronologically and antichronologically), and then merges their representations.\n",
        "- By processing a sequence both ways, a bidirectional RNN can catch patterns that may be overlooked by a unidirectional RNN.\n",
        "\n",
        "<img src=\"https://github.com/ambujtewari/stats315-winter2022/raw/main/images/bidirectional_RNN.png\" width=\"400\"> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAomiHcmzL4R"
      },
      "source": [
        "**Training and evaluating a bidirectional LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "bVn72sVrzL4R"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape = (sequence_length, raw_data.shape[-1]))\n",
        "x = layers.Bidirectional(layers.LSTM(16))(inputs)\n",
        "output = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaY0geZxz1aP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkCk42JjGyi3"
      },
      "source": [
        "- it doesn’t perform as well as the plain LSTM layer.\n",
        "- all the predictive capacity must come from the chronological half of the network\n",
        "- the antichronological half is known to be severely underperforming on this task (again, because the recent past matters much more than the distant past, in this case)\n",
        "- however, the presence of the antichronological half doubles the network’s capacity and contributes to overfitting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tbWvNVrHGHH"
      },
      "source": [
        "\n",
        "**Bidirectional RNNs on text data**\n",
        "\n",
        "- bidirectional RNNs are a great fit for text data, or any other kind of data where order matters, yet where which order you use doesn’t matter.\n",
        "- for a while in 2016, bidirectional LSTMs were considered the state of the art on many natural language processing tasks (before the rise of the Transformer architecture)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYXjZarozL4R"
      },
      "source": [
        "### Going even further\n",
        "\n",
        "- Adjust the number of units in each recurrent layer in the stacked setup, as well as the amount of dropout.\n",
        "- Adjust the learning rate used by the `RMSprop` optimizer, or try a different optimizer.\n",
        "- Try using a stack of `Dense` layers as the regressor on top of the recurrent layer, instead of a single `Dense` layer.\n",
        "- Improve the input to the model: try using longer or shorter sequences or a different sampling rate, or start doing feature engineering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWBhUtixzL4S"
      },
      "source": [
        "## Summary\n",
        "\n",
        "- when approaching a new problem, it’s good to first establish common-sense baselines for your metric of choice. If you don’t have a baseline to beat, you can’t tell whether you’re making real progress.\n",
        "- Try simple models before expensive ones, to make sure the additional expense is justified. Sometimes a simple model will turn out to be your best option.\n",
        "- When you have data where ordering matters, and in particular for timeseries data, recurrent networks are a great fit and easily outperform models that first flat- ten the temporal data.\n",
        "- The two essential RNN layers available in Keras are the LSTM layer and the GRU layer.\n",
        "- To use dropout with recurrent networks, you should use a time-constant dropout mask and recurrent dropout mask. These are built into Keras recurrent layers, so all you have to do is use the `recurrent_dropout` arguments of recurrent layers.\n",
        "- Stacked RNNs provide more representational power than a single RNN layer. They’re also much more expensive and thus not always worth it. Although they offer clear gains on complex problems (such as machine translation), they may not always be relevant to smaller, simpler problems."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}